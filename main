def clean_name(name):
    
    """ Returns a string with non-standard characters removed. """ 
    
    import string
    
    name = name.encode('ascii', errors='ignore') # converts standard ASCII input from Unicode format
    name = name.strip() # removes leading and trailing spaces
    name = name.lower() # converts to lowercase
    
    swap = string.maketrans("-+&. ", "_____") # translation table (from, to)
    punc = string.punctuation # assigns punctuation character set to variable
    punc = punc.replace("-", "") # removes punctuation that will be replaced
    punc = punc.replace("+", "")
    punc = punc.replace("&", "")
    punc = punc.replace(".", "")
    punc = punc.replace("_", "")
    name = string.translate(name, swap, punc) # replaces characters based on translation table then deletes punctuation
    
    mod_name = str(name[0]) # assigns first character of input to empty string
    for i, elem in enumerate(name): # iterates through each element of input string
        if i > 0:
            if elem == name[i-1] and elem == '_': # checks previous element for underscore characters
                continue # skips repeating underscore characters
            else:
                mod_name += elem # builds input string sequentially

    return mod_name # outputs rebuilt (cleaned) user input

def ac(text, color):

    """ (a)dds (c)olor to text, using the standard color name or assigned identification number """

    import csv

    if len(str(color)) > 2:  # check user input for color name or color id
        color = color.title()  # converts to titlecase
    else:
        color = int(color)  # converts to integer
        
    color_table_path = r'\\haleyaldrich.com\share\oak_public\Ian\GIS_Resources\Expressions and Scripts\Arcpy\color_style_reference_2017_0103.csv'  # point to updated color style reference CSV file
    color_table_open = open(color_table_path, 'rb')  # open CSV file to read
    color_palette = csv.DictReader(color_table_open)  # create a dictionary object from CSV file

    for row in color_palette:  # iterate through rows in CSV file
        if color == row['color_name'] or color == int(row['color_code']):  # check user input against color name or color ID
            label_colored = "<CLR RED='{}' GREEN='{}' BLUE='{}'>".format(row['red_value'], row['green_value'], row['blue_value']) + text + "</CLR>"  # retrieve RGB color values
            break  # stop iterating through rows in CSV file
        else:
            label_colored = "<CLR RED='{}' GREEN='{}' BLUE='{}'>".format(0, 0, 0) + text + "</CLR>"  # display black label if unmatched

    return label_colored  # output colored label
    
def ab(text):

    """ (a)dds (b)old to text """

    label_bold = "<BOL>" + text + "</BOL>"

    return label_bold
    
def ai(text):

    """ (a)dds (i)talics to text """

    label_italics = "<ITA>" + text + "</ITA>"

    return label_italics
    
def au(text):

    """ (a)dds (u)nderline to text """

    label_underline = "<UND>" + text + "</UND>"

    return label_underline

def exceed_mcl_ca(result, analyte):

    """ bolds values exceeding California maximum contaminant levels (CA MCLs) for drinking water, October 2018 """

    import csv

    analyte = analyte.title()  # converts analyte to titlecase
    result = float(result)

    mcl_table_path = r'\\haleyaldrich.com\share\oak_public\Ian\GIS_Resources\Expressions and Scripts\Arcpy\mcl_reference_2018_10.csv'  # point to updated MCL reference file
    mcl_table_open = open(mcl_table_path, 'rb')  # open CSV file to read
    mcls = csv.DictReader(mcl_table_open)  # create a dictionary object from CSV file

    for row in mcls:  # iterate through rows in CSV file
        if analyte == row['analyte']:  # check user input against analyte name
            value_exceed = float(row['mcl_ca'])  # pull MCL from California MCLs (or EPA MCLs, as row['mcl_epa'])
            break  # stop iterating through rows in CSV file
        else:
            continue

    if result > value_exceed:
        label_exceed = "<BOL>{0}</BOL>".format(result)  # apply BOLD to values exceeding threshold value
    else:
        label_exceed = "{0}".format(result)  # display standard label if unmatched

    return label_exceed  # output exceedance label
    
def exceed_mcl_epa(result, analyte):

    """ bolds values exceeding federal maximum contaminant levels (EPA MCLs) for drinking water, October 2018 """

    import csv

    analyte = analyte.title()  # converts analyte to titlecase
    result = float(result)

    mcl_table_path = r'\\haleyaldrich.com\share\oak_public\Ian\GIS_Resources\Expressions and Scripts\Arcpy\mcl_reference_2018_10.csv'  # point to updated MCL reference file
    mcl_table_open = open(mcl_table_path, 'rb')  # open CSV file to read
    mcls = csv.DictReader(mcl_table_open)  # create a dictionary object from CSV file

    for row in mcls:  # iterate through rows in CSV file
        if analyte == row['analyte']:  # check user input against analyte name
            value_exceed = float(row['mcl_epa'])  # pull MCL from EPA MCLs (or California MCLs, as row['mcl_ca'])
            break  # stop iterating through rows in CSV file
        else:
            continue

    if result > value_exceed:
        label_exceed = "<BOL>{0}</BOL>".format(result)  # apply BOLD to values exceeding threshold value
    else:
        label_exceed = "{0}".format(result)  # display standard label if unmatched

    return label_exceed  # output exceedance label

def exceed_esl_gw(result, analyte):

    """ bolds values exceeding California San Francisco Regional Water Quality Control Board Tier 1 ESLs (Tier 1 ESLs) for groundwater, February 2016 Rev 3 """

    import csv

    analyte = analyte.upper()  # converts analyte to uppercase
    result = float(result)

    esl_table_path = r'\\haleyaldrich.com\share\oak_public\Ian\GIS_Resources\Expressions and Scripts\Arcpy\esl_reference_2018_10.csv'  # point to updated MCL reference file
    esl_table_open = open(esl_table_path, 'rb')  # open CSV file to read
    esls = csv.DictReader(esl_table_open)  # create a dictionary object from CSV file

    for row in esls:  # iterate through rows in CSV file
        if analyte == row['analyte'].upper():  # check user input against analyte name
            value_exceed = float(row['esl_gw'])  # pull ESL for Groundwater
            break  # stop iterating through rows in CSV file
        else:
            continue

    if result > value_exceed:
        label_exceed = "<BOL>{0}</BOL>".format(result)  # apply BOLD to values exceeding threshold value
    else:
        label_exceed = "{0}".format(result)  # display standard label if unmatched

    return label_exceed  # output exceedance label
    
def exceed_esl_soil(result, analyte):

    """ bolds values exceeding California San Francisco Regional Water Quality Control Board Tier 1 ESLs (Tier 1 ESLs) for soil, February 2016 Rev 3 """

    import csv

    analyte = analyte.upper()  # converts analyte to uppercase
    result = float(result)

    esl_table_path = r'\\haleyaldrich.com\share\oak_public\Ian\GIS_Resources\Expressions and Scripts\Arcpy\esl_reference_2018_10.csv'  # point to updated MCL reference file
    esl_table_open = open(esl_table_path, 'rb')  # open CSV file to read
    esls = csv.DictReader(esl_table_open)  # create a dictionary object from CSV file

    for row in esls:  # iterate through rows in CSV file
        if analyte == row['analyte'].upper():  # check user input against analyte name
            value_exceed = float(row['esl_soil'])  # pull ESL for Soil
            break  # stop iterating through rows in CSV file
        else:
            continue

    if result > value_exceed:
        label_exceed = "<BOL>{0}</BOL>".format(result)  # apply BOLD to values exceeding threshold value
    else:
        label_exceed = "{0}".format(result)  # display standard label if unmatched

    return label_exceed  # output exceedance label
    
def exceed_esl_ss(result, analyte):

    """ bolds values exceeding California San Francisco Regional Water Quality Control Board Tier 1 ESLs (Tier 1 ESLs) for subslab and soil gas, February 2016 Rev 3 """

    import csv

    analyte = analyte.upper()  # converts analyte to uppercase
    result = float(result)

    esl_table_path = r'\\haleyaldrich.com\share\oak_public\Ian\GIS_Resources\Expressions and Scripts\Arcpy\esl_reference_2018_10.csv'  # point to updated MCL reference file
    esl_table_open = open(esl_table_path, 'rb')  # open CSV file to read
    esls = csv.DictReader(esl_table_open)  # create a dictionary object from CSV file

    for row in esls:  # iterate through rows in CSV file
        if analyte == row['analyte'].upper():  # check user input against analyte name
            value_exceed = float(row['esl_subslab'])  # pull ESL for Sub-Slab / Soil Gas 
            break  # stop iterating through rows in CSV file
        else:
            continue

    if result > value_exceed:
        label_exceed = "<BOL>{0}</BOL>".format(result)  # apply BOLD to values exceeding threshold value
    else:
        label_exceed = "{0}".format(result)  # display standard label if unmatched

    return label_exceed  # output exceedance label
    
def exceed_esl_ia(result, analyte):

    """ bolds values exceeding California San Francisco Regional Water Quality Control Board Tier 1 ESLs (Tier 1 ESLs) for indoor air, February 2016 Rev 3 """

    import csv

    analyte = analyte.upper()  # converts analyte to uppercase
    result = float(result)

    esl_table_path = r'\\haleyaldrich.com\share\oak_public\Ian\GIS_Resources\Expressions and Scripts\Arcpy\esl_reference_2018_10.csv'  # point to updated MCL reference file
    esl_table_open = open(esl_table_path, 'rb')  # open CSV file to read
    esls = csv.DictReader(esl_table_open)  # create a dictionary object from CSV file

    for row in esls:  # iterate through rows in CSV file
        if analyte == row['analyte'].upper():  # check user input against analyte name
            value_exceed = float(row['esl_indoor_air'])  # pull ESL for Indoor Air
            break  # stop iterating through rows in CSV file
        else:
            continue

    if result > value_exceed:
        label_exceed = "<BOL>{0}</BOL>".format(result)  # apply BOLD to values exceeding threshold value
    else:
        label_exceed = "{0}".format(result)  # display standard label if unmatched

    return label_exceed  # output exceedance label

def attach_coords(fc, spatial_ref=None):
    
    """ adds fields for coordinates, including northings/eastings (feet) and latitude/longitude (decimal degrees) """
    
    coordinate_fields = ("x_coord", "coord_x", "easting", "eastings", "longitude", "x", "y_coord", "coord_y", "northing", "northings", "latitude", "y")  # alternate coordinate field names for comparison
    fc_desc = arcpy.Describe(fc)  
    fc_fields = arcpy.ListFields(fc)
    
    if spatial_ref:  # assigns spatial reference from function argument
        sr = arcpy.SpatialReference(spatial_ref)
        sr_gcs = sr.GCS
    else:  # assigns spatial reference from feature class
        sr = fc_desc.spatialReference
        sr_gcs = sr.GCS
    
    for field_name in fc_fields:  # checks feature class fields for existing coordinate fields
        if field_name.name in coordinate_fields:
            coord_field_exists = True
            break
        else:
            coord_field_exists = False

    if coord_field_exists == False:  # creates coordinate fields within feature class
        arcpy.AddField_management(fc, "x_coord", "DOUBLE")
        arcpy.AddField_management(fc, "y_coord", "DOUBLE")
        arcpy.AddField_management(fc, "latitude", "DOUBLE")
        arcpy.AddField_management(fc, "longitude", "DOUBLE")
        
        if fc_desc.shapeType == "Point" or fc_desc.shapeType == "Polygon":  # checks for either point or polygon feature class
            with arcpy.da.UpdateCursor(fc, ["SHAPE@X", "SHAPE@Y", "x_coord", "y_coord"], "", sr) as update_cursor_ft:  # uses projected coordinate spatial reference
                for row in update_cursor_ft:  # populates fields with northings/eastings
                    row[2] = row[0]  # updates x coordinate
                    row[3] = row[1]  # updates y coordinate
                    update_cursor_ft.updateRow(row)
            with arcpy.da.UpdateCursor(fc, ["SHAPE@X", "SHAPE@Y", "latitude", "longitude"], "", sr_gcs) as update_cursor_dd:  # uses geographic coordinate spatial reference
                for row in update_cursor_dd:  # populates fields with latitude/longitude
                    row[3] = row[0]  # updates x coordinate
                    row[2] = row[1]  # updates y coordinate
                    update_cursor_dd.updateRow(row)
    else:
        print "Coordinate fields exist already - please remove and try again."

def add_fields_line(fc):

    """ Add standard fields to a polyline feature class. """

    fc_path = arcpy.Describe(fc).catalogPath  # derive file path for feature class
    fc_type = arcpy.Describe(fc_path).dataType  # derive spatial data type
    
    if fc_type == 'FeatureClass':  # determine if feature class (geodatabase)
        arcpy.AddField_management(fc, "loc_id", "TEXT", "", "", 40, "", "NULLABLE", "NON_REQUIRED")
        arcpy.AddField_management(fc, "coord_x_start", "DOUBLE", 14, 4, "", "", "NULLABLE", "NON_REQUIRED")
        arcpy.AddField_management(fc, "coord_y_start", "DOUBLE", 14, 4, "", "", "NULLABLE", "NON_REQUIRED")
        arcpy.AddField_management(fc, "coord_x_end", "DOUBLE", 14, 4, "", "", "NULLABLE", "NON_REQUIRED")
        arcpy.AddField_management(fc, "coord_y_end", "DOUBLE", 14, 4, "", "", "NULLABLE", "NON_REQUIRED")
        arcpy.AddField_management(fc, "loc_type", "TEXT", "", "", 60, "", "NULLABLE", "NON_REQUIRED")
        arcpy.AddField_management(fc, "loc_subtype", "TEXT", "", "", 60, "", "NULLABLE", "NON_REQUIRED")
        arcpy.AddField_management(fc, "loc_descr", "TEXT", "", "", 100, "", "NULLABLE", "NON_REQUIRED")
        arcpy.AddField_management(fc, "region", "TEXT", "", "", 40, "", "NULLABLE", "NON_REQUIRED")
        arcpy.AddField_management(fc, "status", "TEXT", "", "", 40, "", "NULLABLE", "NON_REQUIRED")
        arcpy.AddField_management(fc, "visible", "TEXT", "", "", 10, "", "NULLABLE", "NON_REQUIRED")
        arcpy.AddField_management(fc, "source", "TEXT", "", "", 240, "", "NULLABLE", "NON_REQUIRED")
        arcpy.AddField_management(fc, "last_updated", "DATE", "", "", "", "", "NULLABLE", "NON_REQUIRED")
        arcpy.AddField_management(fc, "notes", "TEXT", "", "", 120, "", "NULLABLE", "NON_REQUIRED")
    elif fc_type == 'ShapeFile':  # determine if shapefile
        arcpy.AddField_management(fc, "loc_id", "TEXT", "", "", 40)
        arcpy.AddField_management(fc, "coord_x_start", "DOUBLE", 14, 4)
        arcpy.AddField_management(fc, "coord_y_start", "DOUBLE", 14, 4)
        arcpy.AddField_management(fc, "coord_x_end", "DOUBLE", 14, 4)
        arcpy.AddField_management(fc, "coord_y_end", "DOUBLE", 14, 4)
        arcpy.AddField_management(fc, "loc_type", "TEXT", "", "", 60)
        arcpy.AddField_management(fc, "loc_subtype", "TEXT", "", "", 60)
        arcpy.AddField_management(fc, "loc_descr", "TEXT", "", "", 100)
        arcpy.AddField_management(fc, "region", "TEXT", "", "", 40)
        arcpy.AddField_management(fc, "status", "TEXT", "", "", 40)
        arcpy.AddField_management(fc, "visible", "TEXT", "", "", 10)
        arcpy.AddField_management(fc, "source", "TEXT", "", "", 240)
        arcpy.AddField_management(fc, "last_updated", "DATE")
        arcpy.AddField_management(fc, "notes", "TEXT", "", "", 120)

def add_fields_point(fc):

    """ Add standard fields to a point feature class. """

    fc_path = arcpy.Describe(fc).catalogPath  # derive file path for feature class
    fc_type = arcpy.Describe(fc_path).dataType  # derive spatial data type
    
    if fc_type == 'FeatureClass':  # determine if feature class (geodatabase)
        arcpy.AddField_management(fc, "loc_id", "TEXT", "", "", 40, "", "NULLABLE", "NON_REQUIRED")
        arcpy.AddField_management(fc, "coord_x", "DOUBLE", 14, 4, "", "", "NULLABLE", "NON_REQUIRED")
        arcpy.AddField_management(fc, "coord_y", "DOUBLE", 14, 4, "", "", "NULLABLE", "NON_REQUIRED")
        arcpy.AddField_management(fc, "latitude", "DOUBLE", 12, 8, "", "", "NULLABLE", "NON_REQUIRED")
        arcpy.AddField_management(fc, "longitude", "DOUBLE", 12, 8, "", "", "NULLABLE", "NON_REQUIRED")
        arcpy.AddField_management(fc, "loc_type", "TEXT", "", "", 60, "", "NULLABLE", "NON_REQUIRED")
        arcpy.AddField_management(fc, "loc_subtype", "TEXT", "", "", 60, "", "NULLABLE", "NON_REQUIRED")
        arcpy.AddField_management(fc, "loc_descr", "TEXT", "", "", 100, "", "NULLABLE", "NON_REQUIRED")
        arcpy.AddField_management(fc, "loc_value", "DOUBLE", 12, 3, "", "", "NULLABLE", "NON_REQUIRED")
        arcpy.AddField_management(fc, "region", "TEXT", "", "", 40, "", "NULLABLE", "NON_REQUIRED")
        arcpy.AddField_management(fc, "status", "TEXT", "", "", 40, "", "NULLABLE", "NON_REQUIRED")
        arcpy.AddField_management(fc, "visible", "TEXT", "", "", 10, "", "NULLABLE", "NON_REQUIRED")
        arcpy.AddField_management(fc, "source", "TEXT", "", "", 240, "", "NULLABLE", "NON_REQUIRED")
        arcpy.AddField_management(fc, "last_updated", "DATE", "", "", "", "", "NULLABLE", "NON_REQUIRED")
        arcpy.AddField_management(fc, "notes", "TEXT", "", "", 120, "", "NULLABLE", "NON_REQUIRED")
    elif fc_type == 'ShapeFile':  # determine if shapefile
        arcpy.AddField_management(fc, "loc_id", "TEXT", "", "", 40)
        arcpy.AddField_management(fc, "coord_x", "DOUBLE", 14, 4)
        arcpy.AddField_management(fc, "coord_y", "DOUBLE", 14, 4)
        arcpy.AddField_management(fc, "latitude", "DOUBLE", 12, 8)
        arcpy.AddField_management(fc, "longitude", "DOUBLE", 12, 8)
        arcpy.AddField_management(fc, "loc_type", "TEXT", "", "", 60)
        arcpy.AddField_management(fc, "loc_subtype", "TEXT", "", "", 60)
        arcpy.AddField_management(fc, "loc_descr", "TEXT", "", "", 100)
        arcpy.AddField_management(fc, "loc_value", "DOUBLE", 12, 3)
        arcpy.AddField_management(fc, "region", "TEXT", "", "", 40)
        arcpy.AddField_management(fc, "status", "TEXT", "", "", 40)
        arcpy.AddField_management(fc, "visible", "TEXT", "", "", 10)
        arcpy.AddField_management(fc, "source", "TEXT", "", "", 240)
        arcpy.AddField_management(fc, "last_updated", "DATE")
        arcpy.AddField_management(fc, "notes", "TEXT", "", "", 120)
    
def add_fields_poly(fc):

    """ Add standard fields to a polygon feature class. """
    
    fc_path = arcpy.Describe(fc).catalogPath  # derive file path for feature class
    fc_type = arcpy.Describe(fc_path).dataType  # derive spatial data type
    
    if fc_type == 'FeatureClass':  # determine if feature class (geodatabase)
        arcpy.AddField_management(fc, "loc_id", "TEXT", "", "", 40, "", "NULLABLE", "NON_REQUIRED")
        arcpy.AddField_management(fc, "loc_type", "TEXT", "", "", 60, "", "NULLABLE", "NON_REQUIRED")
        arcpy.AddField_management(fc, "loc_subtype", "TEXT", "", "", 60, "", "NULLABLE", "NON_REQUIRED")
        arcpy.AddField_management(fc, "loc_descr", "TEXT", "", "", 100, "", "NULLABLE", "NON_REQUIRED")
        arcpy.AddField_management(fc, "region", "TEXT", "", "", 40, "", "NULLABLE", "NON_REQUIRED")
        arcpy.AddField_management(fc, "status", "TEXT", "", "", 40, "", "NULLABLE", "NON_REQUIRED")
        arcpy.AddField_management(fc, "visible", "TEXT", "", "", 10, "", "NULLABLE", "NON_REQUIRED")
        arcpy.AddField_management(fc, "source", "TEXT", "", "", 240, "", "NULLABLE", "NON_REQUIRED")
        arcpy.AddField_management(fc, "last_updated", "DATE", "", "", "", "", "NULLABLE", "NON_REQUIRED")
        arcpy.AddField_management(fc, "notes", "TEXT", "", "", 120, "", "NULLABLE", "NON_REQUIRED")
    elif fc_type == 'ShapeFile':  # determine if shapefile
        arcpy.AddField_management(fc, "loc_id", "TEXT", "", "", 40)
        arcpy.AddField_management(fc, "loc_type", "TEXT", "", "", 60)
        arcpy.AddField_management(fc, "loc_subtype", "TEXT", "", "", 60)
        arcpy.AddField_management(fc, "loc_descr", "TEXT", "", "", 100)
        arcpy.AddField_management(fc, "region", "TEXT", "", "", 40)
        arcpy.AddField_management(fc, "status", "TEXT", "", "", 40)
        arcpy.AddField_management(fc, "visible", "TEXT", "", "", 10)
        arcpy.AddField_management(fc, "source", "TEXT", "", "", 240)
        arcpy.AddField_management(fc, "last_updated", "DATE")
        arcpy.AddField_management(fc, "notes", "TEXT", "", "", 120)

def update_id(fc, id_field='loc_id', amount=1, delimiter='-'):

    """ Updates a numbered sample ID by a specified amount. """
    
    fc_fields = [f.name for f in arcpy.ListFields(fc)]
    
    if 'loc_id_rev' not in fc_fields:
        arcpy.AddField_management(fc, 'loc_id_rev', 'TEXT', '', '', 30)

    with arcpy.da.UpdateCursor(fc, [id_field, 'loc_id_rev']) as update_cursor:
        for row in update_cursor:
            sample = str(row[0])
            prefix = sample[:sample.rfind(delimiter)]
            final_element = len(sample.split(delimiter)) - 1
            try:
                suffix = int(sample.split(delimiter)[final_element]) + amount
                if suffix < 10:
                    combined = [prefix, '0' + str(suffix)]
                else:
                    combined = [prefix, str(suffix)]
                row[1] = delimiter.join(combined)
            except ValueError:
                import string
                for element in sample[::-1]:
                    if element not in string.digits:
                        recommended_split = element
                        break
                print "Location ({0}) cannot be split with the '{1}' character. Please attempt using '{2}' as the delimiter.".format(sample, delimiter, recommended_split)
            update_cursor.updateRow(row)

def update_id_nwse(fc, prefix='HA-'):

    """ Updates numbered sample IDs by location, descending from northwest position to southeast position. """
    
    cursor_fields = ['loc_id_rev', 'longitude', 'latitude']
    coord_fields = ['SHAPE@Y', 'SHAPE@X', 'latitude', 'longitude']
    gcs = arcpy.Describe(fc).spatialReference.GCS
    order_clause = (None, 'ORDER BY {0} ASC, {1} DESC'.format(arcpy.AddFieldDelimiters(fc, 'longitude'), arcpy.AddFieldDelimiters(fc, 'latitude')))

    if prefix.endswith('-'):
        prefix = prefix.upper()
    else:
        prefix = prefix.upper() + '-'

    fc_fields = [f.name for f in arcpy.ListFields(fc)]
    
    if 'loc_id_rev' not in fc_fields:
        arcpy.AddField_management(fc, 'loc_id_rev', 'TEXT', '', '', 30)
    
    if 'longitude' not in fc_fields:
        arcpy.AddField_management(fc, 'longitude', 'DOUBLE', 12, 8)
    
    if 'latitude' not in fc_fields:
        arcpy.AddField_management(fc, 'latitude', 'DOUBLE', 12, 8)
    
    with arcpy.da.UpdateCursor(fc, coord_fields, spatial_reference=gcs) as coord_updates:
        for row in coord_updates:
            row[2] = row[0]
            row[3] = row[1]
            coord_updates.updateRow(row)
    
    counter = 1
    with arcpy.da.UpdateCursor(fc, cursor_fields, sql_clause=order_clause) as order_updates:
        for row in order_updates:
            if counter < 10:
                row[0] = prefix + '0' + str(counter)
            else:
                row[0] = prefix + str(counter)
            order_updates.updateRow(row)
            counter += 1
            
def update_id_nesw(fc, prefix='HA-'):

    """ Updates numbered sample IDs by location, descending from northeast position to southwest position. """
    
    cursor_fields = ['loc_id_rev', 'longitude', 'latitude']
    coord_fields = ['SHAPE@Y', 'SHAPE@X', 'latitude', 'longitude']
    gcs = arcpy.Describe(fc).spatialReference.GCS
    order_clause = (None, 'ORDER BY {0} DESC, {1} DESC'.format(arcpy.AddFieldDelimiters(fc, 'longitude'), arcpy.AddFieldDelimiters(fc, 'latitude')))

    if prefix.endswith('-'):
        prefix = prefix.upper()
    else:
        prefix = prefix.upper() + '-'

    fc_fields = [f.name for f in arcpy.ListFields(fc)]
    
    if 'loc_id_rev' not in fc_fields:
        arcpy.AddField_management(fc, 'loc_id_rev', 'TEXT', '', '', 30)
    
    if 'longitude' not in fc_fields:
        arcpy.AddField_management(fc, 'longitude', 'DOUBLE', 12, 8)
    
    if 'latitude' not in fc_fields:
        arcpy.AddField_management(fc, 'latitude', 'DOUBLE', 12, 8)
    
    with arcpy.da.UpdateCursor(fc, coord_fields, spatial_reference=gcs) as coord_updates:
        for row in coord_updates:
            row[2] = row[0]
            row[3] = row[1]
            coord_updates.updateRow(row)
    
    counter = 1
    with arcpy.da.UpdateCursor(fc, cursor_fields, sql_clause=order_clause) as order_updates:
        for row in order_updates:
            if counter < 10:
                row[0] = prefix + '0' + str(counter)
            else:
                row[0] = prefix + str(counter)
            order_updates.updateRow(row)
            counter += 1
            
def update_id_swne(fc, prefix='HA-'):

    """ Updates numbered sample IDs by location, descending from southwest position to northeast position. """
    
    cursor_fields = ['loc_id_rev', 'longitude', 'latitude']
    coord_fields = ['SHAPE@Y', 'SHAPE@X', 'latitude', 'longitude']
    gcs = arcpy.Describe(fc).spatialReference.GCS
    order_clause = (None, 'ORDER BY {0} ASC, {1} ASC'.format(arcpy.AddFieldDelimiters(fc, 'longitude'), arcpy.AddFieldDelimiters(fc, 'latitude')))

    if prefix.endswith('-'):
        prefix = prefix.upper()
    else:
        prefix = prefix.upper() + '-'

    fc_fields = [f.name for f in arcpy.ListFields(fc)]
    
    if 'loc_id_rev' not in fc_fields:
        arcpy.AddField_management(fc, 'loc_id_rev', 'TEXT', '', '', 30)
    
    if 'longitude' not in fc_fields:
        arcpy.AddField_management(fc, 'longitude', 'DOUBLE', 12, 8)
    
    if 'latitude' not in fc_fields:
        arcpy.AddField_management(fc, 'latitude', 'DOUBLE', 12, 8)
    
    with arcpy.da.UpdateCursor(fc, coord_fields, spatial_reference=gcs) as coord_updates:
        for row in coord_updates:
            row[2] = row[0]
            row[3] = row[1]
            coord_updates.updateRow(row)
    
    counter = 1
    with arcpy.da.UpdateCursor(fc, cursor_fields, sql_clause=order_clause) as order_updates:
        for row in order_updates:
            if counter < 10:
                row[0] = prefix + '0' + str(counter)
            else:
                row[0] = prefix + str(counter)
            order_updates.updateRow(row)
            counter += 1
            
def update_id_senw(fc, prefix='HA-'):

    """ Updates numbered sample IDs by location, descending from southeast position to northwest position. """
    
    cursor_fields = ['loc_id_rev', 'longitude', 'latitude']
    coord_fields = ['SHAPE@Y', 'SHAPE@X', 'latitude', 'longitude']
    gcs = arcpy.Describe(fc).spatialReference.GCS
    order_clause = (None, 'ORDER BY {0} DESC, {1} ASC'.format(arcpy.AddFieldDelimiters(fc, 'longitude'), arcpy.AddFieldDelimiters(fc, 'latitude')))

    if prefix.endswith('-'):
        prefix = prefix.upper()
    else:
        prefix = prefix.upper() + '-'

    fc_fields = [f.name for f in arcpy.ListFields(fc)]
    
    if 'loc_id_rev' not in fc_fields:
        arcpy.AddField_management(fc, 'loc_id_rev', 'TEXT', '', '', 30)
    
    if 'longitude' not in fc_fields:
        arcpy.AddField_management(fc, 'longitude', 'DOUBLE', 12, 8)
    
    if 'latitude' not in fc_fields:
        arcpy.AddField_management(fc, 'latitude', 'DOUBLE', 12, 8)
    
    with arcpy.da.UpdateCursor(fc, coord_fields, spatial_reference=gcs) as coord_updates:
        for row in coord_updates:
            row[2] = row[0]
            row[3] = row[1]
            coord_updates.updateRow(row)
    
    counter = 1
    with arcpy.da.UpdateCursor(fc, cursor_fields, sql_clause=order_clause) as order_updates:
        for row in order_updates:
            if counter < 10:
                row[0] = prefix + '0' + str(counter)
            else:
                row[0] = prefix + str(counter)
            order_updates.updateRow(row)
            counter += 1
